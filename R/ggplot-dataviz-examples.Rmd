---
title: "Portfolio: ggplot, tidyverse, caret/randomForest and gganimate"
author: "Alice Kemp"
output: github_document
---

```{r setup, include=FALSE}
if (!("librarian" %in% rownames(utils::installed.packages()))) {
  utils::install.packages("librarian")}
librarian::shelf(tidyverse, haven, mosaic, foreach, stargazer, gganimate, rpart, rpart.plot, caret, dplyr, mosaic, here, rsample, modelr, purrr, randomForest, gbm, pdp, clusterR, cluster, clue, factoextra, lme4, viridis, ggspatial, basemaps, sf, rgeos, maptools, fdm2id, ggmap, scales, vip, kable, kableExtra)

my_theme = theme_minimal(base_family = "Arial Narrow", base_size = 12) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold", size = rel(1.5)),
        plot.subtitle = element_text(face = "plain", size = rel(1.0), color = "grey60"),
        plot.caption = element_text(face = "italic", size = rel(0.7), 
                                    color = "grey60", hjust = 0),
        legend.title = element_text(face = "bold"),
        strip.text = element_text(face = "bold", size = rel(1.1), hjust = 0),
        axis.title = element_text(face = "bold"))

my_scatter_theme = theme_gray(base_family = "Arial Narrow", base_size = 12) +
  theme(
        plot.title = element_text(face = "bold", size = rel(1.5)),
        plot.subtitle = element_text(face = "plain", size = rel(0.8), color = "grey60"),
        plot.caption = element_text(face = "italic", size = rel(0.7), 
                                    color = "grey60", hjust = 0),
        legend.title = element_text(face = "bold"),
        axis.title = element_text(face = "bold"))

my_scatter_theme2 = theme_gray(base_family = "Arial Narrow", base_size = 12) +
  theme(
        plot.title = element_text(face = "bold", size = rel(1.5), color = "white"),
        plot.subtitle = element_text(face = "plain", size = rel(0.8), color = "white"),
        plot.caption = element_text(face = "italic", size = rel(0.7), 
                                    color = "white", hjust = 0),
        legend.title = element_text(face = "bold", color = "white"),
        legend.text = element_text(color = "white"),
        legend.key = element_blank(),
        axis.title = element_text(face = "bold", color = "white"),
        axis.line.x.bottom = element_line(color="white", size = 0.3),
        axis.line.y.left =element_line(color="white", size = 0.3),
        axis.text = element_text(color="white"),
        panel.background = element_rect(fill = '#444569', color = "#444569"),
        legend.background = element_rect(fill = '#444569', color = "#444569" ),
        plot.background = element_rect(fill = '#444569', color = "#444569"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())

```


## **Predictive model building: green certification**
### Introduction
Pricing rental terms for office buildings in the commercial real estate sector is a complex, multifaceted problem that incorporates a variety of attributes including asset class, age, renovation status, number of floors, location, and the availability of amenities. Within an asset class and submarket, asking rates for office space tend to vary greatly based on these differing characteristics. In this study, we investigate how a building's "green" rating impacts its revenue, calculated as the building's rent per square foot multiplied by its occupancy rate. As efforts to increase sustainability by adding environmentally features that certify a building to be LEED or Energystar certified, the financial impacts and returns to investment become increasingly relevant to a building's landlord. 

### Data
The data used in this study covers 7,894 properties extracted from a leading commercial real estate database. The property attributes included are geographic cluster, size, year-over-year local employment growth, rent per square foot, leasing rate, stories, age, renovation status, asset class, green rating, amenities, annual demand for cooling, annual demand for heating, annual precipitation, utility costs, and local market average rent. Of the 7,894 properties included in the original data, 685 buildings are LEED or Energystar certified, representing approximately 8.7%. 

### Methodology
First, the data was cleaned to remove missing values and filtered to include only buildings with full service gross rents to better compare across properties. After filtering, the data set narrowed minimally to 7,546 total properties, including 640 green rated properties. Diving deeper into the data, we find that the proportion of green rated buildings is larger in Class A properties with 17.2% of buildings being LEED or Energystar certified compared to only 2.8% of Class B properties. This trend was utilized in the model analysis to investigate whether or not green rated buildings had higher revenues than others, both over all asset classes and specifically within Class A properties. After creating the model, figures of actual versus predicted price were created to visualize the distribution of revenues across green ratings. Furthermore, a variable importance plot and a partial dependence plot was created to investigate the relative predictive power of individual attributes in the model and the marginal effects of these attributes on revenue. 

```{r, echo = FALSE, message = FALSE, warning = FALSE}
data = read_csv(here(("data/greenbuildings.csv")), na = "NA", show_col_types = FALSE) %>%
  filter(net == 0) %>% 
  select(-cluster) %>%
  mutate(
    rev_psf = (Rent*(leasing_rate/100))) 
data = na.omit(data)

## create prop table of class a and green
class_green = table(data$class_a, data$class_b, data$green_rating)
props = data.frame(prop.table(class_green, margin = 1))
colnames(props) = c("Class_A","Class_B", "Green_Certified", "Proportion")
props = props %>%
  filter(!row_number() %in% c(4,8))
props$Proportion = scales::percent(props$Proportion)
kable(props, digits = 2, caption = "Table 1.1: Proportion of Green Rated Buildings by Asset Class")

# train test splits
set.seed(123)
green_split = initial_split(data, 0.8)
green_train = training(green_split)
green_test = testing(green_split)

# Random forest model
green_forest = randomForest(rev_psf ~ . -CS_PropertyID -Rent -leasing_rate, data = green_train, na.action = na.omit, mtry = 6, ntree=100, cv.folds = 5)
yhat_forest = predict(green_forest, newdata = green_test)
yhat_forest = na.omit(yhat_forest)
rmse_forest = sqrt(mean((yhat_forest - green_test$rev_psf)^2))
kable(rmse_forest, digits = 4, caption = "Random Forest RMSE")

test_pred = green_test %>%
  mutate(
    yhat = yhat_forest,
    resid = yhat_forest - rev_psf
  )

### plot predicted with green certification vs. none 
ggplot(data = test_pred, aes(x=yhat, y=rev_psf, color = as.factor(green_rating))) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1, size = 0.5, linetype = "dashed", color = "gray80", alpha = 0.4) +
  scale_color_viridis(option = "mako", begin = 0.1, end = 0.7, alpha = 0.8, discrete = TRUE, labels = c("None", "Green")) + 
  ggtitle("Predicted vs. Actual Revenue PSF", subtitle = "Green rated buildings do not tend to outperform other buildings.") +
  xlab("Predicted ($/sf)") + 
  ylab("Actual ($/sf)") + 
  labs(color="Green Rating") + 
  my_scatter_theme2

### Class A only 
ggplot(data = subset(test_pred, class_a == 1), aes(x=yhat, y=rev_psf, color = as.factor(green_rating))) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1, size = 0.5, linetype = "dashed", color = "gray80", alpha = 0.4) +
  scale_color_viridis(option = "mako", begin = 0.1, end = 0.7, alpha = 0.8, discrete = TRUE, labels = c("None", "Green")) + 
  ggtitle("Predicted vs. Actual Revenue PSF (Class A)", subtitle = "Green rated buildings do not tend to outperform other class A buildings.") +
  xlim(0,75) + 
  ylim(0,75) + 
  xlab("Predicted ($/sf)") + 
  ylab("Actual ($/sf)") + 
  labs(color="Green Rating") + 
  my_scatter_theme2

# Boxplot plot by green rating
ggplot(data = subset(test_pred, class_a == 1), aes(x=green_rating, y=yhat, color = as.factor(green_rating))) +
  geom_boxplot(fill = "#444569") + 
  scale_color_viridis(option = "mako", begin = 0.1, end = 0.7, alpha = 0.8, discrete = TRUE, labels = c("None", "Green")) + 
  ggtitle("Predicted vs. Actual Revenue PSF (Class A)", subtitle = "Green rated buildings do not tend to outperform other class A buildings.") +
  xlab("") + 
  ylab("Predicted ($/sf)") + 
  scale_x_discrete(breaks = c("0", "1")) + 
  labs(color="Green Rating") + 
  my_scatter_theme2
```


### Conclusion
To build the best predictive model of revenue based on the given features, a random forest model was created using an 80% train-test split for cross validation purposes. Within the random forest model, 5-fold cross validation was used to prevent overfitting of the training data. The model was then stress tested using the remaining test data set, resulting in an RMSE of approximately $6.81/sf. Next, the data was plotted with actual revenue of the test data against predicted revenue to showcase model accuracy and any trends regarding green rating's impact on revenue. If LEED/Energystar rated buildings did garner higher rents, we would see an outsize population of green buildings on the graph where actual and/or predicted rents are higher. However, we do not observe such a trend in the overall data.  Next, we dug deeper into the Class A data specifically, which tend to have a higher proportion of green rated buildings than Class B or C properties. However, we again do not observe an abnormally large amount of green rated buildings in the upper ranges of predicted or actual revenue, indicating that green rating has a minimal, if any, effect on a building's revenue.    
  To further catalyze on this question, a partial dependence plot was created to determine the marginal effect that a building being green rated has on revenue. From the figure, we see there is a slight increase in revenue for green buildings of approximately \text{$}0.34/sf. Looking at the variable importance plot, we see that market rent, size, stories, and age have the highest predictive power based on our model. Overall, we find no significant evidence that green rated buildings garner higher revenues than other buildings.  

## **Data visualization: Flights at ABIA**

Analyzing flight data from the ABIA airport in Austin, Texas, we investigate trends in airline consistency measured by the average net delay (arrival delay minus departure delay) by day of week. As observed in the figure below, the most consistent airlines were ExpressJet (XE), Southwest Airlines (WN), and American Airlines (AA). These airlines were the most unchanged across days and tended to have shorter tails in the positive net delay direction. On the other hand, the least consistent airlines included Atlantic Southeast Airlines (EV) and Northwest Airlines (NW), and Jetstream International (OH) which tended to have higher variation in net delays and larger right tails. 

```{r abia, echo = FALSE, warning = FALSE, message=FALSE}
ABIA = read_csv(here("data/ABIA.csv"), show_col_types = FALSE) %>%
  select(DayOfWeek, UniqueCarrier, ArrDelay, DepDelay, Origin, Dest) %>%
  filter(Origin == "AUS") %>%
  mutate(delay_total = ArrDelay - DepDelay,
         DayOfWeek = recode_factor(factor(DayOfWeek), 
                            "1"="Monday",
                            "2"="Tuesday",
                            "3"="Wednesday",
                            "4"="Thursday",
                            "5"="Friday",
                            "6"="Saturday",
                            "7"="Sunday"),
         DayOfWeek = fct_relevel(DayOfWeek, 
                                 "Monday", "Tuesday", "Wednesday", 
                                 "Thursday", "Friday", "Saturday", 
                                 "Sunday"))
attach(ABIA)

gganimate = ggplot(ABIA, aes(x=delay_total, y=UniqueCarrier, fill = stat(x))) +
  geom_density_ridges_gradient(rel_min_height = 0.01, scale = 2, show.legend = FALSE) +
  scale_fill_viridis(option = "plasma", alpha = 0.9, discrete = FALSE, direction= -1) + 
  xlim(-40,100) + 
  transition_states(DayOfWeek, transition_length = 1, state_length = 1) + 
  labs(
    title  = "ABIA Outbound Flights: Net delay by carrier",
    subtitle = "Day of Week: {closest_state}",
    caption = "The most consistent airlines are ExpressJet (XE), Southwest Airlines (WN), and American Airlines (AA), while net delays for \n Atlantic Southeast Airlines (EV) and Northwest Airlines (NW) tend to vary more between days.") + 
  xlab("Net Delay (min)") + 
  ylab("Carrier") + 
  my_theme
animate(gganimate)
gganimate
```


## **Predictive model building: California housing**
### Introduction
The aim of this analysis is to predict median house value of California residential homes by census tract based on a selection of characteristics in each census tract including median age, population, number of households, number of rooms and bedrooms, and median income.    
* longitude, latitude: coordinates of the geographic centroid of the census tract  
* housingMedianAge: median age in years of all residential households in the census tract  
* population: total population of the tract  
* households: total number of households in the tract  
* totalRooms, totalBedrooms: total number of rooms and bedrooms for households in the tract  
* medianIncome: median household income in USD for all households in the tract  
* medianHouseValue: median market value of all households in the tract  

### Data
The data set used in this analysis includes information on 20,640 census tracts in the state of California. The data was filtered to remove missing values and the totalBedrooms and totalRooms variables were normalized by dividing by the number of households in each tract. 

### Methodology
First, the centroids of each cluster were mapped and colored according to their median house value. Then, a random forest model was created to predict median house value based on all above attributes. An 80% train-test split was utilized to prevent overfitting of data. When stress tested on the test set data, the random forest model generated an out-of-sample fit of approximately $49,651.00. The predicted test set values were then mapped with a color scale representing median house value. Next, the residuals for each census tract were mapped with a color scale representing the error generated from the random forest model. Finally, a variable importance plot was created to show the variables with the most predictive power in projecting median house value.  
```{r, echo = FALSE, warning=FALSE, message=FALSE}
# load data and remove NAs
ca_housing = read_csv(here(("data/CAhousing.csv")), na = "NA", show_col_types = FALSE)
ca_housing = na.omit(ca_housing)
ca_housing$totalBedrooms = (ca_housing$totalBedrooms)/(ca_housing$households)
ca_housing$totalRooms = (ca_housing$totalRooms)/(ca_housing$households)
ca_housing = ca_housing %>%
  rename(
    bedroomsPerHousehold = totalBedrooms,
    roomsPerHousehold = totalRooms
  )

# plot house value data on map  
m = get_stamenmap(bbox = c(left = -128.00, bottom = 32.54, right = -110.00, top = 42.20),
          maptype = "terrain",
          color = "bw",
          crop = FALSE,
          zoom = 8)
ggmap(m) + 
  geom_point(data = ca_housing, aes(x = longitude, y = latitude, color = medianHouseValue, alpha = 0.8)) + 
  scale_color_viridis(option = "mako", label = dollar_format()) + 
  my_scatter_theme + 
  guides(alpha="none") + 
  labs(color = "median value") +
  scale_x_discrete(labels = NULL, breaks = NULL) +
  scale_y_discrete(labels = NULL, breaks = NULL) +
  xlab("") + 
  ylab("") + 
  ggtitle("Median Residential Home Values in CA",
          subtitle = "Residential house values are highest near California's coastline, with the most expensive \n homes clustering around the state's economic hubs of Los Angeles and the Bay Area.")

# split into train test 
set.seed(123)
house_split = initial_split(ca_housing, 0.8)
house_train = training(house_split)
house_test = testing(house_split)

# create RF model 
forest_house = randomForest(medianHouseValue ~ ., data = house_train, mtry = 8, ntree = 50)
yhat_train = predict(forest_house, house_train) # in sample fit 
rmse_train = mean((yhat_train - house_train$medianHouseValue)^2) %>% sqrt

yhat_forest = predict(forest_house, house_test) # out of sample fit 
rmse_forest = mean((yhat_forest - house_test$medianHouseValue)^2) %>% sqrt
house_pred = house_test %>% cbind(yhat_forest)

# plot predicted values
ggmap(m) + 
  geom_point(data = house_pred, aes(x = longitude, y = latitude, color = yhat_forest, alpha = 0.8)) + 
  scale_color_viridis(option = "mako", labels = dollar_format()) + 
  my_scatter_theme + 
  guides(alpha="none") + 
  labs(color = "predicted value") +
  scale_x_discrete(labels = NULL, breaks = NULL) +
  scale_y_discrete(labels = NULL, breaks = NULL) +
  xlab("") + 
  ylab("") + 
  ggtitle("Predicted Median Residential Home Values in CA",
          subtitle = "Median residential home values predicted using Random Forest model with 50 trees .")

# plot residuals/errors
house_err = house_pred %>% 
  mutate(
    resid = abs(yhat_forest - medianHouseValue)
  )
ggmap(m) + 
  geom_point(data = house_err, aes(x = longitude, y = latitude, color = resid, alpha = 0.7)) + 
  scale_color_viridis(option = "inferno", labels = dollar_format()) + 
  my_scatter_theme + 
  guides(alpha="none") +
  labs(color = "error") + 
  scale_x_discrete(labels = NULL, breaks = NULL) +
  scale_y_discrete(labels = NULL, breaks = NULL) + 
  xlab("") + 
  ylab("") + 
  ggtitle("Predicted Error for Residential Home Values in CA",
          subtitle = "Residuals tend to be larger in California's biggest cities along the coast, areas that also garner the state's highest median prices.")
```


### Conclusion
From the first figure, we observe that there are two obvious clusters of high median home values located near the economic hubs of Los Angeles and San Francisco. Near these clusters, we also observe the largest errors from our random forest model, indicating that our model performs worse in predicting home values in the upper quantiles of median home values. In the final figure, we visualize the predictive power of the Random Forest model's features using a variable importance plot. From this plot, we conclude that a census tract's median income, geographic location, and median age are the most important features in predicting median house value, with population, number of households, and rooms/bedrooms per household ranking among the lowest in terms of predictive power. These results tend to support the underlying data trends with higher income census tracts being associated with higher median home prices in the Los Angeles and San Francisco areas.  



## **KNN Model**
The 350 trim level yields a higher optimal value of k, equal to 32. This may be due to the fact that there is less variance in the data for 350 trim models than for 65 AMG models. Thus, the 350 KNN model can optimize with a higher value of k (more neighbors, but lower sd) to minimize error as compared to the KNN model for the 65 AMG cars.    
```{r sclass, echo = FALSE, warning = FALSE, message=FALSE}
# Trim level: 350 
sclass = read_csv(here("data/sclass.csv"), show_col_types = FALSE) %>%
  select(trim, mileage, price) %>%
  filter(trim %in% c(350,"65 AMG"))
attach(sclass)
sclass350 = sclass %>%
  filter(trim==350)

# create train/test splits
set.seed(123)
sclass350_split = initial_split(sclass350, prop = 0.8)
sclass350_train = training(sclass350_split)
sclass350_test = testing(sclass350_split)

# KNN models
rmse_out350 = foreach(i=2:100, .combine='c') %do% {
  # train the model and calculate RMSE on the test set
  knn_model = knnreg(price ~ mileage, data=sclass350_train, k = i)
  modelr::rmse(knn_model, sclass350_test)
} 
##### 
# repeat for 65 AMG trim level 
#####
sclass65 = sclass %>%
  filter(trim=="65 AMG")

sclass65_split = initial_split(sclass65, prop = 0.8)
sclass65_train = training(sclass65_split)
sclass65_test = testing(sclass65_split)

rmse_out65 = foreach(i=2:100, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage, data=sclass65_train, k = i)
  rmse(knn_model, sclass65_test)} 

# plot K vs. RMSE for both trim levels
k_vals = seq(2,100,1)
df = data.frame(k_vals, rmse_out350, rmse_out65) 
ggplot(df) + 
  geom_line(aes(x = k_vals, y = rmse_out350, color = "350"), size = 1.5, alpha = 0.8) + 
  geom_line(aes(x = k_vals, y = rmse_out65, color = "65 AMG"), size = 1.5, alpha = 0.8) + 
  scale_color_manual("",
                     breaks = c("350", "65 AMG"),
                     values = c("darkorange2","orangered2")) + 
  my_theme + 
  xlab("K") + 
  ylab("RMSE") + 
  labs(title = "KNN Model: K vs. RMSE") 

#####
# Trim level: 350
#####

# find optimal K (minimum RMSE)
optimal_k = df %>%
  select(k_vals, rmse_out350) %>%
  arrange(rmse_out350) %>%
  top_n(1)

# attach predictions to the test df
knn1 = knnreg(price ~ mileage, data=sclass350_train, k = 17)

sclass350_test = sclass350_test %>%
  mutate(price_pred = predict(knn1, sclass350_test))

# plot data and KNN model fit 
ggplot(data = sclass350) + 
  geom_point(aes(x =  mileage, y = price), alpha=0.2) + 
  geom_line(data = sclass350_test, aes(x = mileage, y = price_pred), color='darkorange2', size=1.5) +
  my_theme + 
  labs(
    title = "Mercedes S Class: Mileage vs. Price",
    subtitle = "Trim level: 350 | KNN Model (K=17)")

#####
# Trim level: 65 AMG
#####
# find optimal K (minimum RMSE) 
optimal_k2 = df %>%
  select(k_vals, rmse_out65) %>%
  arrange(rmse_out65)
# attach predictions to the test df
knn2 = knnreg(price ~ mileage, data=sclass65_train, k = 16)

sclass65_test = sclass65_test %>%
  mutate(price_pred = predict(knn2, sclass65_test))

ggplot(data = sclass65) + 
  geom_point(data = sclass65, aes(x =  mileage, y = price), alpha=0.2) +
  geom_line(data = sclass65_test, aes(x = mileage, y = price_pred), color='orangered2', size=1.5) +
  my_theme + 
  labs(
    title = "Mercedes S Class: Mileage vs. Price",
    subtitle = "Trim level: 65 AMG | KNN Model (K=16)") 

```


##**CapMetro Passenger Analysis in Austin, Texas**
```{r, echo = FALSE, warning = FALSE, message = FALSE}
capmetro_UT = read_csv(here(("data/capmetro_UT_raw.csv")), show_col_types = FALSE) 
capmetro_UT %>%
  mutate(across(day_of_week, factor, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")),
         across(month, factor, levels = c("Sep", "Oct", "Nov"))) %>%
  group_by(hour_of_day, day_of_week, month) %>%
  summarize(avg_boardings = mean(boarding)) %>%
ggplot(aes(x=hour_of_day,y=avg_boardings, color = month)) + 
  geom_line() + 
  facet_wrap(vars(day_of_week),nrow=2) + 
  scale_color_manual(values = c("steelblue1", "royalblue1", "mediumblue")) +
  my_theme + 
  ggtitle("Capmetro UT average boardings",
          subtitle = "Passenger demand is highest on weekdays and peaks during the evening between 4:00 and 6:00 pm") + 
    xlab("Hour of Day") + 
    ylab("Average Boardings")

capmetro_UT %>%
  separate(col = timestamp, into = c("date", "hourwindow"), sep = "\\ ") %>%
  group_by(temperature, weekend) %>%
ggplot(aes(x=temperature,y=boarding, color = weekend)) + 
  geom_point(alpha = 0.6, size = 0.9) + 
  facet_wrap(vars(hour_of_day),nrow=4) + 
  scale_color_manual(values=c("steelblue2","mediumblue")) + 
  my_scatter_theme + 
  ggtitle("Temperature vs. Capmetro UT boardings by hour",
          subtitle = "Passenger demand is higher on weekdays, peaking during evening commute periods. \n Temperature appears to have little impact on number of passenger boardings") + 
  labs(
    x = "Temperature (Â°F)",
    y = "Total Boardings"
  )
```






